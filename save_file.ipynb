{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = { 'LR': LinearRegression(), 'SVR': SVR(), }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_intercept = [True, False]\n",
    "normalize = [True, False]\n",
    "params_LR = dict( fit_intercept = fit_intercept, normalize = normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = ['linear', 'rbf', 'poly']\n",
    "C_list = [10, 100]\n",
    "ep_list = [0.1, 1, 5]\n",
    "gamma = [0.01, 0.1]\n",
    "degree = [2, 3]\n",
    "params_SVR = dict( kernel = kernel, C = C_list, epsilon = ep_list, gamma = gamma, degree = degree )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "for EST in regression:\n",
    "    model = regression[EST]\n",
    "    if (EST == 'LR'):\n",
    "        params = params_LR\n",
    "    #else:\n",
    "    #    params = params_SVR\n",
    "\n",
    "    grid = GridSearchCV( estimator=model, n_jobs = 1,verbose = 10,cv = k,scoring = 'neg_mean_squared_error',param_grid=params )\n",
    "    \n",
    "\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best params: ',grid_result.best_params_)\n",
    "print('Best score: ', grid_result.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBF_model = SVR(kernel = 'rbf', C = 100, epsilon = 0.1, gamma = 0.01, degree = 2)\n",
    "RBF_model.fit(X_train,Y_train)\n",
    "RBF_pred = RBF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RBF_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_mean = []\n",
    "bar_std = []\n",
    "bar_param = []\n",
    "bar_rank_test = []\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "rank_tests = grid_result.cv_results_['rank_test_score']\n",
    "\n",
    "\n",
    "for mean, stdev,rank_test_score, param in zip(means, rank_tests,stds, params):\n",
    "    print(\"%f (%f), %f with: %r\" % (mean, stdev, rank_test_score ,param))\n",
    "    bar_mean.append(mean)\n",
    "    bar_std.append(stdev)\n",
    "    bar_rank_test.append(rank_test_score)\n",
    "    bar_param.append(param)\n",
    "\n",
    "from matplotlib.pylab import rcParams   \n",
    "import matplotlib as mpl\n",
    "\n",
    "x = np.arange(len(bar_mean))\n",
    "w = 0.5\n",
    "fig, ax = plt.subplots()\n",
    "fig = plt.title('Criterion : grid_Search')\n",
    "rect1 = plt.bar(x-w/2,bar_mean,w,color = 'b')\n",
    "rect2 = plt.bar(x+w/2,bar_std,w,color = 'r')\n",
    "rect3 = plt.bar(x,bar_rank_test,w,color = 'g')\n",
    "ax.set_xticks(x, labels= bar_param,rotation = 90,fontsize = 60)\n",
    "mpl.rcParams['figure.figsize'] = 100,50 \n",
    "plt.subplots_adjust(bottom=0.50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d72b21489300652f2337cd7f80c57cc00ce6bbc92cf98d285c178d0a8ced433"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
